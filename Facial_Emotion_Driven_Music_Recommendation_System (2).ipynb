{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jf483BPCiRf7"
      },
      "outputs": [],
      "source": [
        "!pip install librosa soundfile gradio opencv-python-headless deepface\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8ATnzbTiT40",
        "outputId": "1a88f911-d176-4288-ecaf-6d2d66350c54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25-12-26 04:02:18 - Directory /root/.deepface has been created\n",
            "25-12-26 04:02:18 - Directory /root/.deepface/weights has been created\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import gradio as gr\n",
        "import cv2\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from deepface import DeepFace\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqhzTpihiWB8",
        "outputId": "98999d5a-9f0f-4d87-e9ce-871f29455fde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7gK5DhMiXsk"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = \"/content/drive/MyDrive/genres\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJzl_-oQiawb"
      },
      "outputs": [],
      "source": [
        "mood_mapping = {\n",
        "    \"happy\": [\"pop\", \"disco\", \"reggae\"],\n",
        "    \"sad\": [\"blues\", \"classical\"],\n",
        "    \"energetic\": [\"rock\", \"metal\", \"hiphop\"],\n",
        "    \"calm\": [\"jazz\", \"country\"]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1C3jthGicJL"
      },
      "outputs": [],
      "source": [
        "def extract_features(file_path):\n",
        "    try:\n",
        "        y, sr = librosa.load(file_path, duration=30)\n",
        "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
        "        return np.mean(mfcc.T, axis=0)\n",
        "    except:\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ls8kbtvBijNz",
        "outputId": "bc4277a7-f29c-4183-b5f6-60f2110ef4d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hiphop: 100 files\n",
            "disco: 100 files\n",
            "classical: 100 files\n",
            "metal: 100 files\n",
            "rock: 100 files\n",
            "jazz: 100 files\n",
            "blues: 100 files\n",
            "reggae: 100 files\n",
            "Total samples loaded: 800\n"
          ]
        }
      ],
      "source": [
        "features = []\n",
        "labels = []\n",
        "\n",
        "for mood, genres in mood_mapping.items():\n",
        "    for genre in genres:\n",
        "        genre_path = os.path.join(DATASET_PATH, genre)\n",
        "\n",
        "        if not os.path.exists(genre_path):\n",
        "            continue\n",
        "\n",
        "        files = [f for f in os.listdir(genre_path) if f.endswith(\".au\")]\n",
        "        print(f\"{genre}: {len(files)} files\")\n",
        "\n",
        "        for file in files:\n",
        "            path = os.path.join(genre_path, file)\n",
        "            feat = extract_features(path)\n",
        "            if feat is not None:\n",
        "                features.append(feat)\n",
        "                labels.append(mood)\n",
        "\n",
        "print(\"Total samples loaded:\", len(features))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1N7ZgNhcij37",
        "outputId": "109ff39b-9205-4814-e84c-efb3ec8e4239"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Random Forest trained successfully\n"
          ]
        }
      ],
      "source": [
        "X = np.array(features)\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(labels)\n",
        "\n",
        "model = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=25,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model.fit(X, y)\n",
        "print(\" Random Forest trained successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qIcl_Kgipt7"
      },
      "outputs": [],
      "source": [
        "def detect_mood_from_selfie(image):\n",
        "    try:\n",
        "        result = DeepFace.analyze(\n",
        "            img_path=image,\n",
        "            actions=['emotion'],\n",
        "            enforce_detection=False\n",
        "        )\n",
        "\n",
        "        emotion = result[0]['dominant_emotion']\n",
        "\n",
        "        if emotion == \"happy\":\n",
        "            return \"happy\"\n",
        "        elif emotion == \"sad\":\n",
        "            return \"sad\"\n",
        "        elif emotion in [\"angry\", \"fear\", \"disgust\"]:\n",
        "            return \"angry\"\n",
        "        else:\n",
        "            return \"calm\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"DeepFace error:\", e)\n",
        "        return \"calm\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vK9Tu8cgiqWj"
      },
      "outputs": [],
      "source": [
        "def get_playlist_for_mood(mood):\n",
        "    playlist = []\n",
        "\n",
        "    for genre in mood_mapping[mood]:\n",
        "        folder = os.path.join(DATASET_PATH, genre)\n",
        "        files = [f for f in os.listdir(folder) if f.endswith(\".au\")]\n",
        "\n",
        "        for f in files:\n",
        "            playlist.append(os.path.join(folder, f))\n",
        "\n",
        "    random.shuffle(playlist)\n",
        "    return playlist\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y45SxS89isws"
      },
      "outputs": [],
      "source": [
        "def play_song_by_index(playlist, index):\n",
        "    index = index % len(playlist)\n",
        "    path = playlist[index]\n",
        "\n",
        "    data, sr = sf.read(path)\n",
        "    out = \"/content/output.wav\"\n",
        "    sf.write(out, data, sr)\n",
        "\n",
        "    return out, os.path.basename(path), index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nomw4Nr4iu3T"
      },
      "outputs": [],
      "source": [
        "def start_jukebox(image):\n",
        "    mood = detect_mood_from_selfie(image)\n",
        "\n",
        "    playlist = get_playlist_for_mood(mood)\n",
        "    audio, song_name, index = play_song_by_index(playlist, 0)\n",
        "\n",
        "    return (\n",
        "        f\"Mood Detected: {mood}\",\n",
        "        audio,\n",
        "        song_name,\n",
        "        playlist,\n",
        "        index\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msNGV1rqixAD"
      },
      "outputs": [],
      "source": [
        "def next_song(playlist, index):\n",
        "    audio, song_name, new_index = play_song_by_index(playlist, index + 1)\n",
        "    return audio, song_name, new_index\n",
        "\n",
        "def previous_song(playlist, index):\n",
        "    audio, song_name, new_index = play_song_by_index(playlist, index - 1)\n",
        "    return audio, song_name, new_index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 733
        },
        "id": "KvVoBlsciy-M",
        "outputId": "a51e4cfc-a009-47a7-eb9f-753cd347e6fd"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://97f027da1fc6cc071e.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://97f027da1fc6cc071e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25-12-26 04:07:05 - ðŸ”— facial_expression_model_weights.h5 will be downloaded from https://github.com/serengil/deepface_models/releases/download/v1.0/facial_expression_model_weights.h5 to /root/.deepface/weights/facial_expression_model_weights.h5...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://github.com/serengil/deepface_models/releases/download/v1.0/facial_expression_model_weights.h5\n",
            "To: /root/.deepface/weights/facial_expression_model_weights.h5\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.98M/5.98M [00:00<00:00, 11.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "with gr.Blocks() as ui:\n",
        "    gr.Markdown(\"## ðŸŽ§ Mood Awakening Jukebox\")\n",
        "\n",
        "    image = gr.Image(type=\"numpy\", label=\"Take a Selfie\")\n",
        "\n",
        "    mood_box = gr.Textbox(label=\"Detected Mood\")\n",
        "    audio = gr.Audio(label=\"Playing Song\")\n",
        "    song_name = gr.Textbox(label=\"GTZAN File\")\n",
        "\n",
        "    playlist_state = gr.State([])\n",
        "    index_state = gr.State(0)\n",
        "\n",
        "    start_btn = gr.Button(\"â–¶ï¸ Start Music\")\n",
        "    prev_btn = gr.Button(\"â®ï¸ Previous\")\n",
        "    next_btn = gr.Button(\"â­ï¸ Next\")\n",
        "\n",
        "    start_btn.click(\n",
        "        start_jukebox,\n",
        "        inputs=image,\n",
        "        outputs=[mood_box, audio, song_name, playlist_state, index_state]\n",
        "    )\n",
        "\n",
        "    next_btn.click(\n",
        "        next_song,\n",
        "        inputs=[playlist_state, index_state],\n",
        "        outputs=[audio, song_name, index_state]\n",
        "    )\n",
        "\n",
        "    prev_btn.click(\n",
        "        previous_song,\n",
        "        inputs=[playlist_state, index_state],\n",
        "        outputs=[audio, song_name, index_state]\n",
        "    )\n",
        "\n",
        "ui.launch(debug=True)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}